{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coderified/NLP_Repo/blob/main/NLP_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c54c63bc",
        "outputId": "0ccc553e-26f5-44d6-e925-cc4fc438ef6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "pqU9akmsG-XT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, GRU, Dense, Activation, Dropout, Embedding\n",
        "from keras.layers import BatchNormalization\n",
        "# from tensorflow.keras.utils import np_utils # np_utils is deprecated, use tf.keras.utils instead if needed\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence\n",
        "# from tensorflow.keras.preprocessing.text import text # Corrected import path\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "FMUeLW54IZ5o",
        "outputId": "975e2637-d8ee-4ac1-b13d-38158d2b4bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                               text author\n",
              "0  id26305  This process, however, afforded me no means of...    EAP\n",
              "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
              "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db27205e-87f3-481b-8442-46cdf8c75c70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db27205e-87f3-481b-8442-46cdf8c75c70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db27205e-87f3-481b-8442-46cdf8c75c70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db27205e-87f3-481b-8442-46cdf8c75c70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1b2eedeb-f2c4-4e84-8949-fe539818da6a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b2eedeb-f2c4-4e84-8949-fe539818da6a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1b2eedeb-f2c4-4e84-8949-fe539818da6a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 19579,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19579,\n        \"samples\": [\n          \"id15695\",\n          \"id07954\",\n          \"id16303\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19579,\n        \"samples\": [\n          \"The gigantic magnitude and the immediately available nature of the sum, dazzled and bewildered all who thought upon the topic.\",\n          \"Shall I disturb this calm by mingling in the world?\",\n          \"He had seen so many customs and witnessed so great a variety of moral creeds that he had been obliged to form an independant one for himself which had no relation to the peculiar notions of any one country: his early prejudices of course influenced his judgement in the formation of his principles, and some raw colledge ideas were strangely mingled with the deepest deductions of his penetrating mind.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"EAP\",\n          \"HPL\",\n          \"MWS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/spooky-author-identification/train/train.csv'\n",
        "test_path = '/content/drive/MyDrive/spooky-author-identification/test/test.csv'\n",
        "samplesub_path = '/content/drive/MyDrive/spooky-author-identification/sample_submission/sample_submission.csv'\n",
        "\n",
        "train = pd.read_csv(file_path)\n",
        "test = pd.read_csv(test_path)\n",
        "ss = pd.read_csv(samplesub_path)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error Metric - Multi Class Log loss\n"
      ],
      "metadata": {
        "id": "yk0shImLPoVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
        "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
        "    :param actual: Array containing the actual target classes\n",
        "    :param predicted: Matrix with class predictions, one probability per class\n",
        "    \"\"\"\n",
        "    # Convert 'actual' to a binary array if it's not already:\n",
        "    if len(actual.shape) == 1:\n",
        "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
        "        for i, val in enumerate(actual):\n",
        "            actual2[i, val] = 1\n",
        "        actual = actual2\n",
        "\n",
        "    clip = np.clip(predicted, eps, 1 - eps)\n",
        "    rows = actual.shape[0]\n",
        "    vsota = np.sum(actual * np.log(clip))\n",
        "    return -1.0 / rows * vsota"
      ],
      "metadata": {
        "id": "JPYkf9tfN7iY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(train['author'])"
      ],
      "metadata": {
        "id": "eaqTSb57P0zf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(train.text.values, y,\n",
        "                                                  stratify=y,\n",
        "                                                  random_state=42,\n",
        "                                                  test_size=0.1, shuffle=True)"
      ],
      "metadata": {
        "id": "US-DAHgSP9V6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text values from train df is split and stored in xtrain and xval, and y is the label encoded values"
      ],
      "metadata": {
        "id": "eKBipCeyRD-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xvalid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYqmEx-wP_I5",
        "outputId": "5460c3a7-65c7-4bc0-eaf0-4b21c0dde3c7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1958,)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfv = TfidfVectorizer(min_df=3,  max_features=None,\n",
        "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), use_idf=True,smooth_idf=True,sublinear_tf=True,stop_words = 'english')\n",
        "\n",
        "tfv.fit(list(xtrain)+list(xvalid))\n",
        "xtrain_tfv = tfv.transform(xtrain)\n",
        "xvalid_tfv = tfv.transform(xvalid)"
      ],
      "metadata": {
        "id": "pnxk5vQFQ7gu"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Parameter                 | Description                                                                                                                  |\n",
        "| ------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |\n",
        "| `min_df=3`                | **Ignore terms that appear in fewer than 3 documents**. Helps remove noise and rare terms.                                   |\n",
        "| `max_features=None`       | No cap on the vocabulary size. If you'd used, say, `max_features=5000`, it would keep only the top 5,000 terms by frequency. |\n",
        "| `strip_accents='unicode'` | Normalize unicode characters (e.g., convert é → e). Useful for multilingual or accented text.                                |\n",
        "| `analyzer='word'`         | Tokenize text at the **word** level (default).                                                                               |\n",
        "| `token_pattern=r'\\w{1,}'` | A custom regex to define what a \"word\" is. `\\w{1,}` means: any word with at least 1 character (letters/numbers/underscores). |\n",
        "| `ngram_range=(1, 3)`      | Extract **unigrams, bigrams, and trigrams**. So you'll get tokens like: \"hello\", \"hello world\", \"hello world again\".         |\n",
        "| `use_idf=True`            | Use **inverse document frequency** — core part of TF-IDF. Penalizes terms that appear in many documents.                     |\n",
        "| `smooth_idf=True`         | Adds 1 to document frequencies to **avoid divide-by-zero errors** when computing IDF.                                        |\n",
        "| `sublinear_tf=True`       | Applies **logarithmic scaling to term frequency**: `tf = 1 + log(tf)` instead of raw counts. Helps with very frequent words. |\n",
        "| `stop_words='english'`    | Removes common English stopwords like \"the\", \"and\", \"is\", etc., to reduce noise.                                             |\n"
      ],
      "metadata": {
        "id": "a_hURejrTuPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_tfv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVoEhuFdRucb",
        "outputId": "b7e1b98f-0e98-442c-850f-b4c8cfb03f0b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
              "\twith 198521 stored elements and shape (17621, 15102)>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfv.get_feature_names_out()[0:50] # show first 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s1LU5JkSGOP",
        "outputId": "c8a11c7a-604c-4f85-a132-04decc17f7fc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['abandon', 'abandoned', 'abandoning', 'abandonment', 'abaout',\n",
              "       'abbey', 'abdication', 'abdul', 'abdul alhazred', 'abernethy',\n",
              "       'abeyance', 'abhor', 'abhorred', 'abhorrence', 'abhorrent',\n",
              "       'abilities', 'ability', 'abject', 'able', 'abnormal',\n",
              "       'abnormalities', 'abnormality', 'abnormally', 'abode', 'abodes',\n",
              "       'abominable', 'abroad', 'abrupt', 'abruptly', 'abruptness',\n",
              "       'absence', 'absence defects', 'absence defects incongruities',\n",
              "       'absence perdita', 'absent', 'absolute', 'absolutely',\n",
              "       'absolutely necessary', 'absorbed', 'absorbing', 'abstract',\n",
              "       'abstracted', 'abstraction', 'abstruse', 'absurd', 'absurdities',\n",
              "       'absurdity', 'absurdly', 'abundance', 'abundant'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(C=1, solver='liblinear')\n",
        "lr.fit(xtrain_tfv, ytrain)\n",
        "preds = lr.predict_proba(xvalid_tfv) # Use predict_proba to get probabilities since logloss expects the probs in 3 column format here\n",
        "print(\"LogLoss : \",multiclass_logloss(yvalid,preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxo8cMmIUAwz",
        "outputId": "54ec7776-c866-4441-fcb8-63d314bb42dd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogLoss :  0.6260093644831317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zFHvhTsUueI",
        "outputId": "82279508-9a60-404f-e1ee-1e89cc4b9b2a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.64570316, 0.07198908, 0.28230776],\n",
              "       [0.7279392 , 0.11053272, 0.16152808],\n",
              "       [0.59463897, 0.16063728, 0.24472375],\n",
              "       ...,\n",
              "       [0.30960304, 0.23045395, 0.45994301],\n",
              "       [0.27844526, 0.19130916, 0.53024558],\n",
              "       [0.12123526, 0.80918181, 0.06958293]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Venctorizer"
      ],
      "metadata": {
        "id": "HkYB98dSVki1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ctv = CountVectorizer(analyzer = 'word', token_pattern = r'\\w{1,}', ngram_range = (1,3), stop_words = 'english')\n",
        "ctv.fit(list(xtrain)+list(xvalid))\n",
        "xtrain_ctv = ctv.transform(xtrain)\n",
        "xvalid_ctv = ctv.transform(xvalid)\n",
        "\n",
        "clf = LogisticRegression(C=1, solver='liblinear')\n",
        "clf.fit(xtrain_ctv, ytrain)\n",
        "preds = clf.predict_proba(xvalid_ctv)\n",
        "print(\"LogLoss : \",multiclass_logloss(yvalid,preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp2hvFGdU0Nv",
        "outputId": "537f96c2-96ea-4a9d-e7f3-29cd8488abdc"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogLoss :  0.5283148537165375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnb_tfv = MultinomialNB()\n",
        "mnb_tfv.fit(xtrain_tfv, ytrain)\n",
        "preds = mnb_tfv.predict_proba(xvalid_tfv)\n",
        "print(\"LogLoss - NaiveBayes - TFIDF : \",multiclass_logloss(yvalid,preds))\n",
        "\n",
        "mnb_ctv = MultinomialNB()\n",
        "mnb_ctv.fit(xtrain_ctv, ytrain)\n",
        "preds = mnb_ctv.predict_proba(xvalid_ctv)\n",
        "print(\"LogLoss - NaiveBayes - CV : \",multiclass_logloss(yvalid,preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJhBO_0pV2mS",
        "outputId": "f15fa2d4-5489-4922-fa64-bb6c815846ad"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogLoss - NaiveBayes - TFIDF :  0.5778049688756707\n",
            "LogLoss - NaiveBayes - CV :  0.48541492313489554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "wZtnpO2iW_Cr"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(xtrain_tfv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1-xX4YmXgN2",
        "outputId": "899e1d89-3ad5-4486-9297-e999d1188942"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Summary\n",
        ".tocsc() Does What?\tConverts sparse matrix to CSC (column-based format)\n",
        "Why needed here?\tOptimizes XGBoost’s performance, especially with text features\n",
        "When to use it?\tWhen input is large, sparse, and especially when using TF-IDF or similar vectorizers"
      ],
      "metadata": {
        "id": "dcrFMgiPXkgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_tfv = XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8,\n",
        "subsample=0.8, nthread=10, learning_rate=0.1)\n",
        "xgb_tfv.fit(xtrain_tfv.tocsc(), ytrain)\n",
        "preds = xgb_tfv.predict_proba(xvalid_tfv.tocsc())\n",
        "print(\"LogLoss - XGBoost - TFIDF : \",multiclass_logloss(yvalid,preds))\n",
        "\n",
        "xgb_ctv = XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8,\n",
        "subsample=0.8, nthread=10, learning_rate=0.1)\n",
        "xgb_ctv.fit(xtrain_ctv.tocsc(), ytrain)\n",
        "preds = xgb_ctv.predict_proba(xvalid_ctv.tocsc())\n",
        "print(\"LogLoss - XGBoost - CV : \",multiclass_logloss(yvalid,preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7Yv5B2fWXSF",
        "outputId": "da8525db-ba75-4c64-ee1f-8c52c8193251"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogLoss - XGBoost - TFIDF :  0.7833459138127274\n",
            "LogLoss - XGBoost - CV :  0.7731896190451263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WORD VECTOR\n",
        "GLOVE\n",
        "\n",
        "🧠 What is GloVe?\n",
        "GloVe (Global Vectors for Word Representation) is a pretrained word embedding method developed by Stanford NLP. It’s a way to represent words as dense vectors (typically 50 to 300 dimensions), where semantic relationships between words are captured mathematically.\n",
        "\n",
        "Unlike TF-IDF or Bag-of-Words (which are sparse and high-dimensional), GloVe embeddings are:\n",
        "\n",
        "Dense (e.g., 100-dimensional float vectors)\n",
        "\n",
        "Context-aware to some extent (but static per word)\n",
        "\n",
        "Learned from co-occurrence statistics over large corpora like Wikipedia or Common Crawl\n",
        "\n",
        "🧬 How is GloVe Trained?\n",
        "GloVe is trained on a word co-occurrence matrix from a massive corpus.\n",
        "\n",
        "If the word “king” often appears near “queen”, “royal”, and “crown”, their vectors will be close in space.\n",
        "\n",
        "GloVe uses this idea to generate embeddings that:\n",
        "\n",
        "Capture similarity (e.g., man ≈ male)\n",
        "\n",
        "Capture analogies:\n",
        "\n",
        "vec(\"king\") - vec(\"man\") + vec(\"woman\") ≈ vec(\"queen\")\n",
        "\n",
        "📦 GloVe Vector Format\n",
        "Each line in a GloVe file looks like this:\n",
        "\n",
        "arduino\n",
        "Copy\n",
        "Edit\n",
        "word 0.418 0.24968 -0.41242 ... 0.1234\n",
        "The first token is the word\n",
        "\n",
        "The rest are the vector components"
      ],
      "metadata": {
        "id": "B1fbDlwOckg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe embeddings\n",
        "embedding_index = {}\n",
        "\n",
        "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = vector\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "nWuBwBZSYAZX",
        "outputId": "2f2caf49-940b-4d66-d80e-b1abc31502dc"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'glove.6B.100d.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-816005ce046b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membedding_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glove.6B.100d.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glove.6B.100d.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LjOfIvSycs4S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5cFCnpb/lqGJN2wR6hm67",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}